{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46e94d6f",
   "metadata": {},
   "source": [
    "# Livestock dataset extraction\n",
    "\n",
    "Author: Thiago Nascimento (thiago.nascimento@eawag.ch)\n",
    "\n",
    "This notebook is used to retrieve and concatenate the livestock dataset into a table for publication alongisde the used data.\n",
    "\n",
    "## Requirements\n",
    "**Python:**\n",
    "\n",
    "* Python>=3.6\n",
    "* Jupyter\n",
    "* geopandas=0.10.2\n",
    "* numpy\n",
    "* os\n",
    "* pandas=2.1.3\n",
    "* tqdm\n",
    "\n",
    "Check the Github repository for an environment.yml (for conda environments) or requirements.txt (pip) file.\n",
    "\n",
    "**Files:**\n",
    "\n",
    "* GVE_Catchments.shp\n",
    "\n",
    "\n",
    "**Directory:**\n",
    "\n",
    "* Clone the GitHub directory locally\n",
    "* Place any third-data variables in their respective directory.\n",
    "* ONLY update the \"PATH\" variable in the section \"Configurations\", with their relative path to the EStreams directory. \n",
    "\n",
    "\n",
    "## References\n",
    "* \n",
    "## Observations\n",
    "* Part of the data is interpolated. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7648ab",
   "metadata": {},
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f6e053",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm as tqdm\n",
    "import os\n",
    "import warnings\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134a0050",
   "metadata": {},
   "source": [
    "# Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3eb41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only editable variables:\n",
    "# Relative path to your local directory\n",
    "PATH = \"../..\"\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "path_data = r\"C:\\Users\\nascimth\\Documents\\data\\CAMELS_CH_Chem\\data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0c1c1e",
   "metadata": {},
   "source": [
    "* #### The users should NOT change anything in the code below here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d25b417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-editable variables:\n",
    "PATH_OUTPUT = \"results\\Dataset\\catchment_aggregated_data\\livestock_data\"\n",
    "\n",
    "# Set the directory:\n",
    "os.chdir(PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b54907f",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba96cbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "catchments_gve = gpd.read_file(path_data+'\\shapefile_gve\\GVE_Catchments.shp')\n",
    "catchments_gve[\"bafu_id\"] = catchments_gve[\"gauge_id\"]\n",
    "catchments_gve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213e1db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network CAMELS_CH_Chem\n",
    "network_camels_ch_chem = pd.read_excel(path_data+\"\\CAMELS_CH_chem_stations_short_v3.xlsx\", sheet_name='all_5')\n",
    "#network_camels_ch_chem.set_index(\"basin_id\", inplace=True)\n",
    "network_camels_ch_chem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba3e50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The majority is primarly formed by the bafu id, so here we check the oens that ARE NOT:\n",
    "network_camels_ch_chem[network_camels_ch_chem.bafu_id.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a974e855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the DataFrames for achieving the bafu_id ias the last column\n",
    "catchments_gve = pd.merge(catchments_gve, network_camels_ch_chem[['bafu_id', 'basin_id']], on='bafu_id', how='left')\n",
    "catchments_gve = pd.merge(catchments_gve, network_camels_ch_chem[['nawa_id', 'basin_id']], on='nawa_id', how='left')\n",
    "catchments_gve = pd.merge(catchments_gve, network_camels_ch_chem[['naduf_id', 'basin_id']], on='naduf_id', how='left')\n",
    "\n",
    "catchments_gve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594ede0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace all 0s with NaN:\n",
    "catchments_gve.loc[:, ['gauge_id', \"naduf_id\", \"nawa_id\"]] = catchments_gve.loc[:, ['gauge_id', \"naduf_id\", \"nawa_id\"]].replace(0, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23956a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the new 'basin_id' column based on the priority order\n",
    "catchments_gve['basin_id_new'] = np.nan\n",
    "catchments_gve['basin_id_new'] = np.where(\n",
    "    catchments_gve['gauge_id'].notna(), catchments_gve['basin_id_x'],\n",
    "    np.where(\n",
    "        catchments_gve['nawa_id'].notna(), catchments_gve['basin_id_y'],\n",
    "        catchments_gve['basin_id']\n",
    "    )\n",
    ")\n",
    "\n",
    "# Display the updated DataFrame\n",
    "catchments_gve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d38c075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we can check the data\n",
    "catchments_gve[catchments_gve.basin_id_new.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd886701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we solve it manuallly\n",
    "catchments_gve.loc[84, [\"basin_id_new\"]] = 2403.0\n",
    "catchments_gve.loc[110, [\"basin_id_new\"]] = 2622.0\n",
    "\n",
    "catchments_gve[catchments_gve.basin_id_new.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be38f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates based on 'gauge_id'\n",
    "catchments_gve_unique = catchments_gve.drop_duplicates(subset=\"basin_id_new\")\n",
    "catchments_gve_unique.set_index(\"basin_id_new\", inplace=True)\n",
    "catchments_gve_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6fcef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the 2403 (BAFU) since it is empty for our time range, and 2622 (merged with 2243):\n",
    "catchments_gve_unique.drop(2403.0, axis=0, inplace=True)\n",
    "catchments_gve_unique.drop(2622.0, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c22038",
   "metadata": {},
   "outputs": [],
   "source": [
    "catchments_gve_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3249da60",
   "metadata": {},
   "outputs": [],
   "source": [
    "livestock_df = pd.DataFrame(index=network_camels_ch_chem.basin_id.astype(float))\n",
    "\n",
    "livestock_df[['gve_1980_S', 'gve_1985_S', 'gve_1990_S', 'gve_1996_S', 'gve_1997_S', 'gve_1998_S', 'gve_1999_S', 'gve_2000_S', \n",
    "              'gve_2001_S', 'gve_2002_S', 'gve_2003_S', 'gve_2004_S', 'gve_2005_S', 'gve_2006_S',\n",
    "       'gve_2007_S', 'gve_2008_S', 'gve_2009_S', 'gve_2010_S', 'gve_2011_S', 'gve_2012_S', 'gve_2013_S', \n",
    "       'gve_2014_S', 'gve_2015_S', 'gve_2016_S', 'gve_2017_S', 'gve_2018_S', 'gve_2019_S', 'gve_2020_S', 'gve_2021_S',\n",
    "       'gve_2022_S',\n",
    "       'gve_1980_h', 'gve_1985_h', 'gve_1990_h',\n",
    "       'gve_1996_h', 'gve_1997_h', 'gve_1998_h', 'gve_1999_h', 'gve_2000_h',\n",
    "       'gve_2001_h', 'gve_2002_h', 'gve_2003_h', 'gve_2004_h', 'gve_2005_h',\n",
    "       'gve_2006_h', 'gve_2007_h', 'gve_2008_h', 'gve_2009_h', 'gve_2010_h',\n",
    "       'gve_2011_h', 'gve_2012_h', 'gve_2013_h', 'gve_2014_h', 'gve_2015_h',\n",
    "       'gve_2016_h', 'gve_2017_h', 'gve_2018_h', 'gve_2019_h', 'gve_2020_h',\n",
    "       'gve_2021_h', 'gve_2022_h']] = catchments_gve_unique[['gve_1980_S', 'gve_1985_S', 'gve_1990_S', 'gve_1996_S', 'gve_1997_S', 'gve_1998_S', 'gve_1999_S', 'gve_2000_S', \n",
    "              'gve_2001_S', 'gve_2002_S', 'gve_2003_S', 'gve_2004_S', 'gve_2005_S', 'gve_2006_S',\n",
    "       'gve_2007_S', 'gve_2008_S', 'gve_2009_S', 'gve_2010_S', 'gve_2011_S', 'gve_2012_S', 'gve_2013_S', \n",
    "       'gve_2014_S', 'gve_2015_S', 'gve_2016_S', 'gve_2017_S', 'gve_2018_S', 'gve_2019_S', 'gve_2020_S', 'gve_2021_S',\n",
    "       'gve_2022_S',\n",
    "       'gve_1980_h', 'gve_1985_h', 'gve_1990_h',\n",
    "       'gve_1996_h', 'gve_1997_h', 'gve_1998_h', 'gve_1999_h', 'gve_2000_h',\n",
    "       'gve_2001_h', 'gve_2002_h', 'gve_2003_h', 'gve_2004_h', 'gve_2005_h',\n",
    "       'gve_2006_h', 'gve_2007_h', 'gve_2008_h', 'gve_2009_h', 'gve_2010_h',\n",
    "       'gve_2011_h', 'gve_2012_h', 'gve_2013_h', 'gve_2014_h', 'gve_2015_h',\n",
    "       'gve_2016_h', 'gve_2017_h', 'gve_2018_h', 'gve_2019_h', 'gve_2020_h',\n",
    "       'gve_2021_h', 'gve_2022_h']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86006bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can have it file by file exported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efad255",
   "metadata": {},
   "outputs": [],
   "source": [
    "livestock_df_sum = pd.DataFrame(index=network_camels_ch_chem.basin_id.astype(float))\n",
    "\n",
    "livestock_df_sum[['gve_1980_S', 'gve_1985_S', 'gve_1990_S', 'gve_1996_S', 'gve_1997_S', 'gve_1998_S', 'gve_1999_S', 'gve_2000_S', \n",
    "              'gve_2001_S', 'gve_2002_S', 'gve_2003_S', 'gve_2004_S', 'gve_2005_S', 'gve_2006_S',\n",
    "       'gve_2007_S', 'gve_2008_S', 'gve_2009_S', 'gve_2010_S', 'gve_2011_S', 'gve_2012_S', 'gve_2013_S', \n",
    "       'gve_2014_S', 'gve_2015_S', 'gve_2016_S', 'gve_2017_S', 'gve_2018_S', 'gve_2019_S', 'gve_2020_S', 'gve_2021_S',\n",
    "       'gve_2022_S']] = catchments_gve_unique[['gve_1980_S', 'gve_1985_S', 'gve_1990_S', 'gve_1996_S', 'gve_1997_S', 'gve_1998_S', 'gve_1999_S', 'gve_2000_S', \n",
    "              'gve_2001_S', 'gve_2002_S', 'gve_2003_S', 'gve_2004_S', 'gve_2005_S', 'gve_2006_S',\n",
    "       'gve_2007_S', 'gve_2008_S', 'gve_2009_S', 'gve_2010_S', 'gve_2011_S', 'gve_2012_S', 'gve_2013_S', \n",
    "       'gve_2014_S', 'gve_2015_S', 'gve_2016_S', 'gve_2017_S', 'gve_2018_S', 'gve_2019_S', 'gve_2020_S', 'gve_2021_S',\n",
    "       'gve_2022_S']]\n",
    "\n",
    "\n",
    "livestock_df_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330d5e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "livestock_df_ha = pd.DataFrame(index=network_camels_ch_chem.basin_id.astype(float))\n",
    "\n",
    "livestock_df_ha[['gve_1980_h', 'gve_1985_h', 'gve_1990_h',\n",
    "       'gve_1996_h', 'gve_1997_h', 'gve_1998_h', 'gve_1999_h', 'gve_2000_h',\n",
    "       'gve_2001_h', 'gve_2002_h', 'gve_2003_h', 'gve_2004_h', 'gve_2005_h',\n",
    "       'gve_2006_h', 'gve_2007_h', 'gve_2008_h', 'gve_2009_h', 'gve_2010_h',\n",
    "       'gve_2011_h', 'gve_2012_h', 'gve_2013_h', 'gve_2014_h', 'gve_2015_h',\n",
    "       'gve_2016_h', 'gve_2017_h', 'gve_2018_h', 'gve_2019_h', 'gve_2020_h',\n",
    "       'gve_2021_h', 'gve_2022_h']] = catchments_gve_unique[['gve_1980_h', 'gve_1985_h', 'gve_1990_h',\n",
    "       'gve_1996_h', 'gve_1997_h', 'gve_1998_h', 'gve_1999_h', 'gve_2000_h',\n",
    "       'gve_2001_h', 'gve_2002_h', 'gve_2003_h', 'gve_2004_h', 'gve_2005_h',\n",
    "       'gve_2006_h', 'gve_2007_h', 'gve_2008_h', 'gve_2009_h', 'gve_2010_h',\n",
    "       'gve_2011_h', 'gve_2012_h', 'gve_2013_h', 'gve_2014_h', 'gve_2015_h',\n",
    "       'gve_2016_h', 'gve_2017_h', 'gve_2018_h', 'gve_2019_h', 'gve_2020_h',\n",
    "       'gve_2021_h', 'gve_2022_h']]\n",
    "\n",
    "livestock_df_ha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b6056e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for basin in tqdm.tqdm(livestock_df.index):\n",
    "    livestock_df_sum_basin = pd.DataFrame(data=livestock_df_sum.loc[basin, :])\n",
    "\n",
    "    # Use regex to extract numeric part from the index\n",
    "    livestock_df_sum_basin.index = livestock_df_sum_basin.index.to_series().str.extract('(\\d+)', expand=False)\n",
    "\n",
    "    # Optionally, convert the index back to numeric type if you want them as integers\n",
    "    livestock_df_sum_basin.index = pd.to_numeric(livestock_df_sum_basin.index)\n",
    "\n",
    "    livestock_df_sum_basin.index.name = \"date\"\n",
    "\n",
    "    livestock_df_sum_basin.columns = [\"gve_sum\"]\n",
    "\n",
    "    livestock_df_sum_basin[\"gve_ha\"] = livestock_df_ha.loc[basin, :].values\n",
    "\n",
    "    livestock_df_sum_basin.index = livestock_df_sum_basin.index.astype(int)\n",
    "\n",
    "    # Generate a full range of years from 1980 to 2019\n",
    "    full_range = pd.DataFrame(index=range(1980, 2021))\n",
    "\n",
    "    # Reindex the dataframe to include all years\n",
    "    livestock_df_sum_basin_interpolated = livestock_df_sum_basin.reindex(full_range.index)\n",
    "\n",
    "    # Interpolate missing values\n",
    "    livestock_df_sum_basin_interpolated = livestock_df_sum_basin_interpolated.interpolate(method='linear')\n",
    "\n",
    "\n",
    "    livestock_df_sum_basin_interpolated = livestock_df_sum_basin_interpolated.round(4)\n",
    "    livestock_df_sum_basin_interpolated.index.name = \"date\"\n",
    "\n",
    "    livestock_df_sum_basin_interpolated.to_csv(PATH_OUTPUT + \"\\\\camels_ch_chem_livestock_\"+str(int(basin))+\".csv\", encoding='latin')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b608e26e",
   "metadata": {},
   "source": [
    "# End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

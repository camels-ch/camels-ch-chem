{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efa5eee1",
   "metadata": {},
   "source": [
    "# Isoscape dataset extraction\n",
    "\n",
    "Author: Martina Kauzlaric (martina.kauzlaric@unibe.ch)\n",
    "\n",
    "This notebook is used to extract data from monthly isoscapes (i.e. isotopic landscapes, which are spatially continuous and georeferenced isotope datasets) of deuterium [‚Ä∞] and oxygen-18 [‚Ä∞] with a resolution of 500m provided by the FOEN into a table for publication alongisde the used data.\n",
    "Stable isotope data in precipitation of the isotope observation network in Switzerland (ISOT), together with several influencing variables (e.g., topographical parameters, climate variables) are used in a multi-regression framework, and the residuals are interpolated by the use of ordinary kriging.\n",
    "Monthly data are available for the years between 2007 and 2023.\n",
    "\n",
    "## Requirements\n",
    "**Python:**\n",
    "\n",
    "* Python=3.13.2\n",
    "* Jupyter\n",
    "* os\n",
    "* numpy=2.2.4\n",
    "* xarray=2024.11.0\n",
    "* pandas=2.2.3\n",
    "* geopandas=1.0.1\n",
    "* cartopy=0.24.1\n",
    "* matplotlib=3.10.0\n",
    "* tqdm=4.67.1\n",
    "\n",
    "Check the Github repository for an environment_landcover.yml (for conda environments) file [for semplicity we use the same environment and that used for extracting the landcover data]\n",
    "\n",
    "**Files:**\n",
    "\n",
    "* ?\n",
    "\n",
    "\n",
    "**Directory:**\n",
    "\n",
    "* Clone the GitHub directory locally\n",
    "* Place any third-data variables in their respective directory.\n",
    "* ONLY update the \"PATH\" variable in the section \"Configurations\", with their relative path to the EStreams directory. \n",
    "\n",
    "## References\n",
    "* Bundesamt f√ºr Umwelt BAFU\n",
    "* Office f√©d√©ral de l'environnement OFEV\n",
    "* Ufficio federale dell'ambiente UFAM\n",
    "* Federal Office for the Environment FOEN\n",
    "* ¬© BAFU\n",
    "* https://www.bafu.admin.ch/bafu/en/home/topics/water/groundwater/groundwater-resources/stable-water-isotopes.html\n",
    "* https://www.bafu.admin.ch/dam/bafu/de/dokumente/hydrologie/externe-studien-berichte/isoscapes_schweiz_endbericht.pdf.download.pdf/isoscapes_schweiz_endbericht.pdf\n",
    "## Observations\n",
    "* Data are only available for catchments inside the national boundaries!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fc37bc",
   "metadata": {},
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0356cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear all variables\n",
    "%reset -f\n",
    "#Import necessary libraries\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "#import xarray as xr\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.geometry import MultiPolygon\n",
    "from shapely.geometry import box\n",
    "import tqdm as tqdm\n",
    "import re\n",
    "import rasterio\n",
    "from rasterio.mask import mask\n",
    "from concurrent.futures import ThreadPoolExecutor # this is to run functions in parallel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960c2972",
   "metadata": {},
   "source": [
    "# Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8872bb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only editable variables:\n",
    "# Set (relative) path to your local directory\n",
    "#PATH = \"../..\"\n",
    "PATH = \"S:\\\\CAMELS-CH\\\\CAMELS-chem\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f10adcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set directories\n",
    "GIS_dir = os.path.join(PATH,\"data\\\\GIS\")\n",
    "# Define shapefile with the catchments\n",
    "catchments_shp = os.path.join(GIS_dir,\"shapefile_catchments\\\\camels_ch_chem_catchment_boundaries.shp\")\n",
    "#Add subfolder to GIS_dir for Isoscape data\n",
    "GIS_dir = os.path.join(GIS_dir, \"Isoscapes\")  \n",
    "PATH_OUTPUT = os.path.join(PATH,\"results\\\\catchment_aggregated_data\\\\isoscapes\")\n",
    "\n",
    "# Create the output directory if it does not exist\n",
    "if not os.path.isdir(PATH_OUTPUT):\n",
    "    os.makedirs(PATH_OUTPUT, exist_ok=True)\n",
    "\n",
    "##Change to directory to where you want to store the results    \n",
    "os.chdir(PATH_OUTPUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14aa5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3073678d",
   "metadata": {},
   "source": [
    "* #### The users should NOT change anything in the code below here. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29e63e6",
   "metadata": {},
   "source": [
    "# Import data\n",
    "* Load catchments and look at full table\n",
    "\n",
    "*Note: data are in LV95/CH1903+, i.e. EPSG 2056*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74cbf3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "catchments = gpd.read_file(catchments_shp)\n",
    "catchments[\"bafu_id\"] = catchments[\"gauge_id\"]\n",
    "catchments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8f779e",
   "metadata": {},
   "source": [
    "Now we get the isoscapes and extract these per catchment.\n",
    "\n",
    "*Note: data are in LV95/CH1903+, i.e. EPSG 2056*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c22a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect directories containing monthly isoscape data\n",
    "ascii_dirs = [d for d in os.listdir(GIS_dir) if \"Monatsraster\" in d]\n",
    "print(ascii_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3627d469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define isotopes to be extracted\n",
    "isotopes = [\"18O\", \"2H\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9245d2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- HELPER FUNCTION FOR ONE CATCHMENT ---\n",
    "def process_catchment(args):\n",
    "    catch_idx, catch, raster_files, isotope, crs, isotope_outdir = args\n",
    "\n",
    "    catch_id = catch[\"gauge_id\"]\n",
    "    catch_geom = gpd.GeoDataFrame([catch], crs=crs)\n",
    "\n",
    "    values = []\n",
    "    months = []\n",
    "\n",
    "    for file_path in raster_files:\n",
    "        month_match = re.search(r\"_(\\d{8})\\.asc$\", file_path)\n",
    "        if not month_match:\n",
    "            continue\n",
    "        date_str = month_match.group(1)\n",
    "        date = pd.to_datetime(date_str, format=\"%Y%m%d\")\n",
    "        months.append(date)\n",
    "\n",
    "        try:\n",
    "            with rasterio.open(file_path) as src:\n",
    "                out_image, _ = mask(src, catch_geom.geometry, crop=True)\n",
    "                out_image = out_image[0]\n",
    "                valid = out_image != src.nodata\n",
    "                if np.any(valid):\n",
    "                    mean_value = float(np.nanmean(out_image[valid]))\n",
    "                else:\n",
    "                    mean_value = np.nan\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Error in file {file_path} for {catch_id}: {e}\")\n",
    "            mean_value = np.nan\n",
    "\n",
    "        values.append(mean_value)\n",
    "\n",
    "    # Save timeseries\n",
    "    df = pd.DataFrame({\n",
    "        \"date\": months,\n",
    "        f\"{isotope}_monthlymean\": values\n",
    "    })\n",
    "    df.to_csv(os.path.join(isotope_outdir, f\"{catch_id}_isoscape.csv\"),\n",
    "              index=False, sep=\";\", float_format=\"%.2f\")\n",
    "    return catch_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe851291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- MAIN LOOP ---\n",
    "if __name__ == \"__main__\":\n",
    "    for isotope in isotopes:\n",
    "        print(f\"\\nüß™ Processing isotope {isotope}...\")\n",
    "\n",
    "        dir_match = [d for d in ascii_dirs if isotope in d]\n",
    "        if not dir_match:\n",
    "            print(f\"‚ö†Ô∏è No directory found for isotope {isotope}\")\n",
    "            continue\n",
    "\n",
    "        ascii_dir = os.path.join(GIS_dir, dir_match[0])\n",
    "        raster_files = sorted([\n",
    "            os.path.join(ascii_dir, f) for f in os.listdir(ascii_dir) if f.endswith(\".asc\")\n",
    "        ])\n",
    "\n",
    "        isotope_outdir = os.path.join(PATH_OUTPUT, isotope)\n",
    "        os.makedirs(isotope_outdir, exist_ok=True)\n",
    "\n",
    "        task_args = [\n",
    "            (idx, row, raster_files, isotope, catchments.crs, isotope_outdir)\n",
    "            for idx, row in catchments.iterrows()\n",
    "        ]\n",
    "\n",
    "        print(f\"üöÄ Launching parallel processing on {min(20, os.cpu_count())} cores...\")\n",
    "\n",
    "        with ThreadPoolExecutor(max_workers=20) as executor:\n",
    "            results = list(tqdm.tqdm(executor.map(process_catchment, task_args),\n",
    "                                     total=len(task_args), desc=f\"Catchments for {isotope}\"))\n",
    "\n",
    "        print(f\"Done with isotope {isotope} ‚Äî {len(results)} catchments processed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341ec3cc",
   "metadata": {},
   "source": [
    "Here  following is the code to loop over one catchment per time [depending on the number of catchments and the number of cores available maybe necessary..]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ed972e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Helper Function ---\n",
    "def extract_mean_per_catchment(raster_fp, catchment_geom):\n",
    "    \"\"\"Returns the mean of raster values within a catchment geometry.\"\"\"\n",
    "    with rasterio.open(raster_fp) as src:\n",
    "        out_image, out_transform = mask(src, catchment_geom.geometry, crop=True)\n",
    "        out_image = out_image[0]  # First band\n",
    "\n",
    "        # Masked values are set to src.nodata\n",
    "        valid = out_image != src.nodata\n",
    "        if np.any(valid):\n",
    "            return float(np.nanmean(out_image[valid]))\n",
    "        else:\n",
    "            return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832a3c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "for isotope in isotopes:\n",
    "    print(f\"\\nüß™ Processing isotope {isotope}...\")\n",
    "\n",
    "    # Find the correct directory for this isotope\n",
    "    dir_match = [d for d in ascii_dirs if isotope in d]\n",
    "    if not dir_match:\n",
    "        print(f\"‚ö†Ô∏è No directory found for isotope {isotope}\")\n",
    "        continue\n",
    "\n",
    "    ascii_dir = os.path.join(GIS_dir, dir_match[0])\n",
    "    raster_files = sorted([os.path.join(ascii_dir, f) for f in os.listdir(ascii_dir) if f.endswith(\".asc\")])\n",
    "\n",
    "    # Create output folder for this isotope\n",
    "    isotope_outdir = os.path.join(PATH_OUTPUT, isotope)\n",
    "    os.makedirs(isotope_outdir, exist_ok=True)\n",
    "\n",
    "    # Loop over catchments\n",
    "    for _, catch in tqdm.tqdm(catchments.iterrows(), total=len(catchments), desc=f\"Catchments for {isotope}\"):\n",
    "        catch_id = catch[\"gauge_id\"]\n",
    "        catch_geom = gpd.GeoDataFrame([catch], crs=catchments.crs)\n",
    "\n",
    "        values = []\n",
    "        months = []\n",
    "\n",
    "        for file_path in raster_files:\n",
    "            # Extract date from filename\n",
    "            month_match = re.search(r\"_(\\d{8})\\.asc$\", file_path)\n",
    "            if not month_match:\n",
    "                continue\n",
    "            date_str = month_match.group(1)\n",
    "            date = pd.to_datetime(date_str, format=\"%Y%m%d\")\n",
    "            months.append(date)\n",
    "\n",
    "            mean_value = extract_mean_per_catchment(file_path, catch_geom)\n",
    "            values.append(mean_value)\n",
    "\n",
    "        # Save timeseries for this catchment\n",
    "        df = pd.DataFrame({\n",
    "            \"date\": months,\n",
    "            f\"{isotope}_monthlymean\": values\n",
    "        })\n",
    "        df.to_csv(os.path.join(isotope_outdir, f\"{catch_id}_isoscape.csv\"),\n",
    "                  index=False, sep=\";\", float_format=\"%.2f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2439bf43",
   "metadata": {},
   "source": [
    "Eventually, we generate the yearly mean isoscapes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0239510e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for isotope in isotopes:\n",
    "    print(f\"\\nüìà Generating yearly summary for {isotope}...\")\n",
    "\n",
    "    # Directory with catchment time series for this isotope\n",
    "    iso_dir = os.path.join(PATH_OUTPUT, isotope)\n",
    "    files = [f for f in os.listdir(iso_dir) if f.endswith(\"_isoscape.csv\")]\n",
    "\n",
    "    # Preallocate result DataFrame\n",
    "    yearly_data = {}\n",
    "\n",
    "    for file in files:\n",
    "        catch_id = file.replace(\"_isoscape.csv\", \"\")\n",
    "        filepath = os.path.join(iso_dir, file)\n",
    "\n",
    "        df = pd.read_csv(filepath, sep=\";\", parse_dates=[\"date\"])\n",
    "        df[\"year\"] = df[\"date\"].dt.year\n",
    "\n",
    "        # Column is like \"18O_monthlymean\" or \"2H_monthlymean\"\n",
    "        val_col = [col for col in df.columns if col.endswith(\"_monthlymean\")][0]\n",
    "\n",
    "        yearly_mean = df.groupby(\"year\")[val_col].mean()\n",
    "        yearly_data[catch_id] = yearly_mean\n",
    "\n",
    "    # Combine into one DataFrame (rows = years, columns = catchments)\n",
    "    yearly_df = pd.DataFrame(yearly_data)\n",
    "    yearly_df.index.name = \"year\"\n",
    "\n",
    "    # Save to CSV\n",
    "    out_fp = os.path.join(PATH_OUTPUT, f\"{isotope}_isoscape_yearly_summary.csv\")\n",
    "    yearly_df.to_csv(out_fp, sep=\";\", float_format=\"%.2f\")\n",
    "\n",
    "    print(f\"Saved yearly summary to: {out_fp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a45aa00",
   "metadata": {},
   "source": [
    "Organize the data as time-series for the dataset (stored at the results folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75c5e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "folder_2h = '../../results/isoscapes/2H'\n",
    "folder_18o = '../../results/isoscapes/18O'\n",
    "output_folder = \"../../results/Dataset/catchment_aggregated_data/rain_water_isotopes\"\n",
    "\n",
    "# Create output folder if it doesn't exist\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# List all files in the 2H folder\n",
    "files_2h = sorted([f for f in os.listdir(folder_2h) if f.endswith('.csv')])\n",
    "\n",
    "for filename in files_2h:\n",
    "    path_2h = os.path.join(folder_2h, filename)\n",
    "    path_18o = os.path.join(folder_18o, filename)\n",
    "\n",
    "    # Read both files\n",
    "    df_2h = pd.read_csv(path_2h, sep=';', parse_dates=['date'])\n",
    "    df_18o = pd.read_csv(path_18o, sep=';', parse_dates=['date'])\n",
    "\n",
    "    # Rename columns\n",
    "    df_2h.rename(columns={'2H_monthlymean': 'delta_2h'}, inplace=True)\n",
    "    df_18o.rename(columns={'18O_monthlymean': 'delta_18o'}, inplace=True)\n",
    "\n",
    "    # Merge on date\n",
    "    df_merged = pd.merge(df_2h, df_18o, on='date')\n",
    "\n",
    "    # Set index\n",
    "    df_merged.set_index('date', inplace=True)\n",
    "    df_merged = df_merged.loc[:\"2020\", :]\n",
    "    # Save the output\n",
    "    output_path = os.path.join(output_folder, f\"camels_ch_chem_rainisotopes_{filename[0:4]}.csv\")\n",
    "    df_merged.to_csv(output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
